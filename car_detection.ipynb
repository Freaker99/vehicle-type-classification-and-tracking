{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1qT0ljzGAMB0inCouexfN8NKoE5T3CTJ_",
      "authorship_tag": "ABX9TyOwdlcj+IsuLxmZFCem396M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Freaker99/car-detection/blob/main/car_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup\n",
        "Mount drive with data."
      ],
      "metadata": {
        "id": "rQwFkaDIZe1_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "7WvVYIGxYMnJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2bc9929-8a82-4e51-f25b-b2c97b2ec994"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.flush_and_unmount()\n",
        "drive.mount('/content/drive')\n",
        "root = '/content/drive/My Drive/car-detection/'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install YOLOv5 package."
      ],
      "metadata": {
        "id": "UKtVzhZLkrv_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install yolov5"
      ],
      "metadata": {
        "id": "0yIDThdVruEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install libriaries, clone GitHub repository, YOLOv5's weeights, install requirements."
      ],
      "metadata": {
        "id": "5B6kx603mfas"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install opencv-python\n",
        "#!pip install torch torchvision\n",
        "#!pip install numpy\n",
        "#!pip install ultralytics\n",
        "\n",
        "#!git clone https://github.com/ultralytics/yolov5\n",
        "#!wget https://github.com/ultralytics/yolov5/releases/download/v5.0/yolov5s.pt\n",
        "#%cd yolov5\n",
        "#!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "okzOlMLANDFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import all dependencies."
      ],
      "metadata": {
        "id": "682CZj19lVqn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import json\n",
        "import glob\n",
        "import shutil\n",
        "import subprocess\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchvision.transforms import transforms\n",
        "from torchvision.transforms.functional import resize\n",
        "from torchvision.models import resnet50\n",
        "from torchvision.datasets.vision import VisionDataset\n",
        "from torch.utils.data import DataLoader\n",
        "from yolov5.models.yolo import Model\n",
        "#from numpy import True\n",
        "from PIL import Image\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "GLkW4yralXLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BDD100KDataset"
      ],
      "metadata": {
        "id": "S5PaGXrLZqjF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BDD100KDataset(VisionDataset):\n",
        "    def __init__(self, labels_file, image_dir, transform=None, target_transform=None, resize_size=(256, 256), crop_size=(224, 224)):\n",
        "        super(BDD100KDataset, self).__init__(image_dir, transform=transform, target_transform=target_transform)\n",
        "        self.labels = self._read_labels(labels_file)\n",
        "        self.images = [item[\"name\"] for item in self.labels]\n",
        "        self.resize_size = resize_size\n",
        "        self.crop_size = crop_size\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image_path = os.path.join(self.root, self.images[index])\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "        image = transforms.Resize(self.resize_size)(image)\n",
        "        image = transforms.RandomCrop(self.crop_size)(image)\n",
        "        label = self.labels[index]\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "        if self.target_transform is not None:\n",
        "            label = self.target_transform(label)\n",
        "        return image, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def _read_labels(self, labels_file):\n",
        "        with open(labels_file, \"r\") as f:\n",
        "            labels = json.load(f)\n",
        "        return labels"
      ],
      "metadata": {
        "id": "SS18orYgUGiw"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rezising images to the same resolution."
      ],
      "metadata": {
        "id": "SbcT1tBLmLbM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transform(image, target):\n",
        "    image = image.resize((224, 224))\n",
        "    image = torch.Tensor(np.array(image)).permute(2, 0, 1) / 255.0  # Konwersja na tensor i normalizacja\n",
        "    target = torch.Tensor(target)\n",
        "    return image, target"
      ],
      "metadata": {
        "id": "wrJvgHA5Ih1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cie偶ki do folder贸w z obrazami\n",
        "image_dir_train = '/content/drive/My Drive/car-detection/images/train/train100k'\n",
        "image_dir_val = '/content/drive/My Drive/car-detection/images/val/'\n",
        "\n",
        "# cie偶ki do plik贸w etykiet\n",
        "train_labels_file = '/content/drive/My Drive/car-detection/labels/det_train.json'\n",
        "val_labels_file = '/content/drive/My Drive/car-detection/labels/det_val.json'\n",
        "\n",
        "# Tworzenie instancji datasetu treningowego i walidacyjnego\n",
        "train_dataset = BDD100KDataset(train_labels_file, image_dir_train, transform=transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.RandomCrop((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "]))\n",
        "val_dataset = BDD100KDataset(val_labels_file, image_dir_val, transform=transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.RandomCrop((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "]))\n",
        "\n",
        "# Definiowanie DataLoader dla treningu i walidacji\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=0, drop_last=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=2, shuffle=False, num_workers=0)"
      ],
      "metadata": {
        "id": "q8YtjtlgLDf9"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validate YOLOv5s on BDD100K val\n",
        "!python '/content/drive/MyDrive/car-detection/yolov5/val.py' --weights '/content/drive/MyDrive/car-detection/yolov5/yolov5s.pt' --data '/content/drive/MyDrive/car-detection/yolov5/models/yolov5s_modified.yaml' --img 640 --half"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wjZ6tKrLbdw",
        "outputId": "7215821f-72e0-481a-cec5-a2b7423f58d6"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mdata=/content/drive/MyDrive/car-detection/yolov5/models/yolov5s_modified.yaml, weights=['/content/drive/MyDrive/car-detection/yolov5/yolov5s.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=drive/MyDrive/car-detection/yolov5/runs/val, name=exp, exist_ok=False, half=True, dnn=False\n",
            "fatal: HEAD is neither a commit nor blob\n",
            "YOLOv5  2023-6-19 Python-3.10.12 torch-2.0.1+cu118 CPU\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/car-detection/labels/val... 0 images, 10000 backgrounds, 0 corrupt: 100% 10000/10000 [00:43<00:00, 231.04it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING 锔 No labels found in /content/drive/MyDrive/car-detection/labels/val.cache. See https://docs.ultralytics.com/yolov5/tutorials/train_custom_data\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/MyDrive/car-detection/labels/val.cache\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0% 0/313 [00:01<?, ?it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/car-detection/yolov5/val.py\", line 409, in <module>\n",
            "    main(opt)\n",
            "  File \"/content/drive/MyDrive/car-detection/yolov5/val.py\", line 380, in main\n",
            "    run(**vars(opt))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/content/drive/MyDrive/car-detection/yolov5/val.py\", line 210, in run\n",
            "    preds, train_out = model(im) if compute_loss else (model(im, augment=augment), None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/drive/MyDrive/car-detection/yolov5/models/common.py\", line 515, in forward\n",
            "    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/drive/MyDrive/car-detection/yolov5/models/yolo.py\", line 209, in forward\n",
            "    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n",
            "  File \"/content/drive/MyDrive/car-detection/yolov5/models/yolo.py\", line 121, in _forward_once\n",
            "    x = m(x)  # run\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/drive/MyDrive/car-detection/yolov5/models/common.py\", line 59, in forward_fuse\n",
            "    return self.act(self.conv(x))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\", line 463, in forward\n",
            "    return self._conv_forward(input, self.weight, self.bias)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\", line 459, in _conv_forward\n",
            "    return F.conv2d(input, weight, bias, self.stride,\n",
            "RuntimeError: \"slow_conv2d_cpu\" not implemented for 'Half'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "mQ_wQgHPneUB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "pin_memory = True\n",
        "\n",
        "# Funkcja treningowa\n",
        "def train(model, train_loader, criterion, optimizer):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for images, labels in tqdm(train_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    return avg_loss"
      ],
      "metadata": {
        "id": "2rDLMBKNne4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicjalizacja modelu YOLOv5\n",
        "model = Model(root + \"yolov5/models/yolov5s.yaml\")\n",
        "\n",
        "# Zaadowanie wstpnie wytrenowanych wag modelu\n",
        "state_dict = torch.load(root + \"yolov5/yolov5s.pt\")\n",
        "model.load_state_dict(state_dict, strict=False)\n",
        "model.to(device)\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Ustawienie trybu trenowania modelu\n",
        "model.train()\n",
        "\n",
        "# Definicja optymalizatora\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Definicja funkcji straty\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Parametry trenowania\n",
        "num_epochs = 10\n",
        "batch_size = 2\n",
        "learning_rate = 0.001\n",
        "\n",
        "\n",
        "\n",
        "# Ptla trenowania\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
        "\n",
        "    # Trening\n",
        "    train_loss = train(model, train_loader, criterion, optimizer)\n",
        "    print(f\"Train Loss: {train_loss:.4f}\")\n",
        "\n",
        "    # Ocena na zbiorze walidacyjnym (opcjonalnie)\n",
        "    # val_loss = evaluate(model, val_loader, criterion)\n",
        "    # print(f\"Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "    print(\"\")\n",
        "\n",
        "# Zapisanie wytrenowanego modelu\n",
        "torch.save(model.state_dict(), \"trained_model.pt\")"
      ],
      "metadata": {
        "id": "J8V_ZSg1lS87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tools"
      ],
      "metadata": {
        "id": "1UsYp3abtjK8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/My Drive/car-detection/yolov5/models/yolov5s_modified.yaml'\n",
        "\n",
        "with open(file_path, 'r') as f:\n",
        "    content = f.read()\n",
        "\n",
        "print(content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSu2wH5VTgla",
        "outputId": "3cf468fc-de26-46ed-8a6e-8bf8373a8625"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# YOLOv5  by Ultralytics, AGPL-3.0 license\n",
            "\n",
            "# Parameters\n",
            "nc: 80  # number of classes\n",
            "depth_multiple: 0.33  # model depth multiple\n",
            "width_multiple: 0.50  # layer channel multiple\n",
            "anchors:\n",
            "  - [10,13, 16,30, 33,23]  # P3/8\n",
            "  - [30,61, 62,45, 59,119]  # P4/16\n",
            "  - [116,90, 156,198, 373,326]  # P5/32\n",
            "\n",
            "# YOLOv5 v6.0 backbone\n",
            "backbone:\n",
            "  # [from, number, module, args]\n",
            "  [[-1, 1, Conv, [64, 6, 2, 2]],  # 0-P1/2\n",
            "   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n",
            "   [-1, 3, C3, [128]],\n",
            "   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n",
            "   [-1, 6, C3, [256]],\n",
            "   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n",
            "   [-1, 9, C3, [512]],\n",
            "   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n",
            "   [-1, 3, C3, [1024]],\n",
            "   [-1, 1, SPPF, [1024, 5]],  # 9\n",
            "  ]\n",
            "\n",
            "# YOLOv5 v6.0 head\n",
            "head:\n",
            "  [[-1, 1, Conv, [512, 1, 1]],\n",
            "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
            "   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n",
            "   [-1, 3, C3, [512, False]],  # 13\n",
            "\n",
            "   [-1, 1, Conv, [256, 1, 1]],\n",
            "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
            "   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n",
            "   [-1, 3, C3, [256, False]],  # 17 (P3/8-small)\n",
            "\n",
            "   [-1, 1, Conv, [256, 3, 2]],\n",
            "   [[-1, 14], 1, Concat, [1]],  # cat head P4\n",
            "   [-1, 3, C3, [512, False]],  # 20 (P4/16-medium)\n",
            "\n",
            "   [-1, 1, Conv, [512, 3, 2]],\n",
            "   [[-1, 10], 1, Concat, [1]],  # cat head P5\n",
            "   [-1, 3, C3, [1024, False]],  # 23 (P5/32-large)\n",
            "\n",
            "   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n",
            "  ]\n",
            "\n",
            "# Train/val/test sets as 1) dir: path/to/imgs, 2) file: path/to/imgs.txt, or 3) list: [path/to/imgs1, path/to/imgs2, ..]\n",
            "path: content/drive/My Drive/car-detection  # dataset root dir\n",
            "train: images/train/train100k  # train images\n",
            "val: images/val\n",
            "test: images/test\n",
            "\n",
            "# Classes\n",
            "names:\n",
            "  0: pedestrian\n",
            "  1: bicycle\n",
            "  2: car\n",
            "  3: motorcycle\n",
            "  5: bus\n",
            "  6: train\n",
            "  7: truck\n",
            "  9: traffic light\n",
            "  11: traffic sign\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_large_file(input_file, output_folder):\n",
        "    with open(input_file, 'r') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    for label in data:\n",
        "        name = label['name'].replace('.jpg', '.txt')\n",
        "        output_path = os.path.join(output_folder, name)\n",
        "\n",
        "        with open(output_path, 'w') as txt_file:\n",
        "            json.dump(label, txt_file)\n",
        "\n",
        "        print(f\"Zapisano plik: {name}\")\n",
        "\n",
        "# Wprowad藕 cie偶k do swojego du偶ego pliku tekstowego\n",
        "#input_file = '/content/drive/My Drive/car-detection/labels/det_val_txt.txt'\n",
        "input_file = '/content/drive/My Drive/car-detection/labels/det_train_txt.txt'\n",
        "\n",
        "# Okrel folder, w kt贸rym bd zapisywane podzielone pliki\n",
        "#output_folder = '/content/drive/My Drive/car-detection/labels/labels_val_txt'\n",
        "output_folder = '/content/drive/My Drive/car-detection/labels/labels_train_txt'\n",
        "\n",
        "# Wywoaj funkcj do podziau pliku\n",
        "split_large_file(input_file, output_folder)"
      ],
      "metadata": {
        "id": "T_eTC-ritjW3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_yolov5(input_folder, output_folder):\n",
        "    # Sownik mapujcy klasy na indeksy w formacie YOLOv5\n",
        "    class_mapping = {\n",
        "        \"pedestrian\": 0,\n",
        "        \"bicycle\": 1,\n",
        "        \"car\": 2,\n",
        "        \"motorcycle\": 3,\n",
        "        \"bus\": 5,\n",
        "        \"train\": 6,\n",
        "        \"truck\": 7,\n",
        "        \"traffic light\": 9,\n",
        "        \"traffic sign\": 11\n",
        "        # Brak klasy \"rider\", bo jest nieistotna\n",
        "    }\n",
        "\n",
        "    # Sprawd藕 istnienie folderu wyjciowego; jeli nie istnieje, utw贸rz go\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "    count = 0\n",
        "   # Przetwarzaj ka偶dy plik w folderze wejciowym\n",
        "    for filename in os.listdir(input_folder):\n",
        "        input_file = os.path.join(input_folder, filename)\n",
        "        output_file = os.path.join(output_folder, filename)\n",
        "\n",
        "        with open(input_file, 'r') as f:\n",
        "            data = json.load(f)\n",
        "            print(\"teraz przetwarzam\" + str(count) + input_file)\n",
        "\n",
        "        # Sprawd藕, czy klucz 'labels' istnieje w danych\n",
        "        if 'labels' in data:\n",
        "            with open(output_file, 'w') as f:\n",
        "                for label in data['labels']:\n",
        "                    category = label.get('category', '')\n",
        "                    if category in class_mapping:\n",
        "                        class_index = class_mapping[category]\n",
        "\n",
        "                        x1 = label['box2d'].get('x1', 0)\n",
        "                        y1 = label['box2d'].get('y1', 0)\n",
        "                        x2 = label['box2d'].get('x2', 0)\n",
        "                        y2 = label['box2d'].get('y2', 0)\n",
        "\n",
        "                        # Oblicz wsp贸rzdne rodka oraz szeroko i wysoko bounding boxa\n",
        "                        width = x2 - x1\n",
        "                        height = y2 - y1\n",
        "                        x_center = x1 + width / 2\n",
        "                        y_center = y1 + height / 2\n",
        "\n",
        "                        # Przeskaluj wsp贸rzdne do zakresu 0-1\n",
        "                        x_center /= 1280\n",
        "                        y_center /= 720\n",
        "                        width /= 1280\n",
        "                        height /= 720\n",
        "\n",
        "                        # Zapisz wynikowy wiersz w formacie YOLOv5\n",
        "                        f.write(f\"{class_index} {x_center} {y_center} {width} {height}\\n\")\n",
        "        else:\n",
        "            print(f\"Brak klucza 'labels' w pliku: {filename}\")\n",
        "\n",
        "        print(f\"Przetworzono plik: {filename}\")\n",
        "        count = count +1\n",
        "\n",
        "# Wprowad藕 cie偶ki do swojego folderu wejciowego i docelowego folderu YOLOv5\n",
        "#input_folder = \"/content/drive/My Drive/car-detection/labels/labels_val_txt\"\n",
        "input_folder = \"/content/drive/My Drive/car-detection/labels/labels_train_txt\"\n",
        "\n",
        "#output_folder = \"/content/drive/My Drive/car-detection/labels/labels_val_txt_yolov5\"\n",
        "output_folder = \"/content/drive/My Drive/car-detection/labels/labels_train_txt_yolov5\"\n",
        "\n",
        "convert_to_yolov5(input_folder, output_folder)"
      ],
      "metadata": {
        "id": "4b9J8xRMZlJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/drive/My Drive/car-detection/labels/det_val.json\"\n",
        "output_folder = \"/content/drive/My Drive/car-detection/labels/labels_val_txt\"\n",
        "\n",
        "json_file = \"/content/drive/My Drive/car-detection/labels/det_val.json\"\n",
        "\n",
        "def create_txt_files(json_file, output_folder):\n",
        "    with open(json_file, 'r') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    for item in data:\n",
        "        if 'name' in item and 'regions' in item:\n",
        "            file_name = item['name'].replace('.jpg', '.txt')\n",
        "            file_path = os.path.join(output_folder, file_name)\n",
        "            with open(file_path, 'w') as txt_file:\n",
        "                for region in item['regions']:\n",
        "                    for line in region.get('lines', []):\n",
        "                        txt_file.write(line + '\\n')\n",
        "    create_txt_files(file_path, output_folder)"
      ],
      "metadata": {
        "id": "w3Q0wykYPRG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check resolution\n",
        "\n",
        "def check_resolution(image_folder):\n",
        "    resolutions = set()\n",
        "\n",
        "    for filename in os.listdir(image_folder):\n",
        "        if filename.endswith(('.png', '.jpg', '.jpeg')):\n",
        "            filepath = os.path.join(image_folder, filename)\n",
        "            with Image.open(filepath) as img:\n",
        "                resolutions.add(img.size)\n",
        "\n",
        "    if len(resolutions) == 1:\n",
        "        print(\"Wszystkie obrazy maj t sam rozdzielczo:\", resolutions.pop())\n",
        "    else:\n",
        "        print(\"Obrazy maj r贸偶ne rozdzielczoci:\", resolutions)\n",
        "\n",
        "image_folder_path = '/content/drive/My Drive/car-detection/images/val'\n",
        "check_resolution(image_folder_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsUGC91FJsY1",
        "outputId": "de04d945-9aa8-4eee-b6bc-b90937e8f933"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wszystkie obrazy maj t sam rozdzielczo: (1280, 720)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show inside of the file\n",
        "\n",
        "#file_path = \"/content/drive/My Drive/car-detection/labels/labels_val_txt/c79e169f-054f74e7.txt\"\n",
        "#file_path = \"/content/drive/My Drive/car-detection/labels/labels_val_txt/b1c66a42-6f7d68ca.txt\"\n",
        "file_path = \"/content/drive/My Drive/car-detection/labels/labels_train_txt/11ecaf4a-837e3550.txt\"\n",
        "with open(file_path, 'r') as f:\n",
        "    content = f.read()\n",
        "\n",
        "print(content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFqVf5S-JWOZ",
        "outputId": "0faac6fa-ba01-45fd-9b0a-008460fd66d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"name\": \"11ecaf4a-837e3550.jpg\", \"attributes\": {\"weather\": \"clear\", \"timeofday\": \"night\", \"scene\": \"highway\"}, \"timestamp\": 10000}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Json syntax check\n",
        "\n",
        "def check_json_syntax(folder_path):\n",
        "    file_names = os.listdir(folder_path)\n",
        "\n",
        "    for file_name in file_names:\n",
        "        file_path = os.path.join(folder_path, file_name)\n",
        "\n",
        "        with open(file_path, 'r') as f:\n",
        "            try:\n",
        "                json.load(f)\n",
        "                print(f\"Plik {file_name} ma poprawn skadni JSON.\")\n",
        "            except json.JSONDecodeError as e:\n",
        "                print(f\"Bd skadni JSON w pliku {file_name}: {e}\")\n",
        "\n",
        "# Wprowad藕 cie偶k do folderu zawierajcego pliki tekstowe\n",
        "#folder_path = \"/content/drive/My Drive/car-detection/labels/labels_val_txt\"\n",
        "folder_path = \"/content/drive/My Drive/car-detection/labels/labels_train_txt\"\n",
        "\n",
        "# Wywoaj funkcj sprawdzajc skadni JSON\n",
        "check_json_syntax(folder_path)"
      ],
      "metadata": {
        "id": "hVTbMTbQKioE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# File exists\n",
        "\n",
        "os.path.exists('/content/drive/My Drive/car-detection/images/train/train100k/8ec22bdd-58cd1abf.jpg')"
      ],
      "metadata": {
        "id": "ZWyM3sCWDQbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove files\n",
        "\n",
        "def remove_files(folder):\n",
        "    file_list = os.listdir(folder)\n",
        "    for file_name in file_list:\n",
        "        file_path = os.path.join(folder, file_name)\n",
        "        os.remove(file_path)\n",
        "        print(f\"Usunito plik: {file_name}\")\n",
        "\n",
        "# Wprowad藕 cie偶k do folderu\n",
        "folder = '/content/drive/My Drive/car-detection/labels/labels_val_txt'\n",
        "\n",
        "# Wywoaj funkcj do usuwania plik贸w\n",
        "remove_files(folder)"
      ],
      "metadata": {
        "id": "OyIucE3cItp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print labels\n",
        "\n",
        "image_dir = \"/content/drive/My Drive/car-detection/images/train/\"\n",
        "labels_file = \"/content/drive/My Drive/car-detection/labels/bdd100k_labels_images_train.json\"  # cie偶ka do pliku z etykietami (dostosuj do swojej struktury danych)\n",
        "\n",
        "# Wczytanie danych etykiet\n",
        "with open(labels_file, \"r\") as f:\n",
        "    labels = json.load(f)\n",
        "\n",
        "# Sprawdzenie informacji o nazwach plik贸w w etykietach\n",
        "for item in labels:\n",
        "    file_name = item[\"name\"]\n",
        "    # Tutaj mo偶esz wydrukowa nazwy plik贸w lub wykona inne operacje na danych etykiet\n",
        "\n",
        "# Por贸wnanie nazw plik贸w obraz贸w z informacjami w etykietach\n",
        "file_list = os.listdir(image_dir)\n",
        "for file_name in file_list:\n",
        "    if file_name not in [item[\"name\"] for item in labels]:\n",
        "        print(\"Brak informacji w etykietach dla pliku:\", file_name)"
      ],
      "metadata": {
        "id": "UgG_irnSYz7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print files\n",
        "\n",
        "image_dir = \"/content/drive/My Drive/car-detection/labels/labels_train_txt\"\n",
        "\n",
        "# Wywietlenie listy plik贸w w folderze\n",
        "file_list = os.listdir(image_dir)\n",
        "for file_name in file_list:\n",
        "    print(file_name)"
      ],
      "metadata": {
        "id": "e2q7cidzsRPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count files\n",
        "\n",
        "#!ls '/content/drive/My Drive/car-detection/labels/labels_train_txt' | wc -l\n",
        "!ls '/content/drive/My Drive/car-detection/labels/labels_train_txt_yolov5' | wc -l\n",
        "#!ls '/content/drive/My Drive/car-detection/images/train/train100k' | wc -l"
      ],
      "metadata": {
        "id": "SXxYvElTIv9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Move files\n",
        "\n",
        "src_folder = '/content/drive/My Drive/car-detection'\n",
        "\n",
        "dst_folder = '/content/drive/My Drive/car-detection'\n",
        "\n",
        "file_list = glob.glob(os.path.join(src_folder, '*.jpg'))\n",
        "batch_size = 100  # Liczba plik贸w w jednej partycji\n",
        "num_batches = len(file_list) // batch_size + 1\n",
        "\n",
        "for i in range(num_batches):\n",
        "    start_idx = i * batch_size\n",
        "    end_idx = start_idx + batch_size\n",
        "    batch_files = file_list[start_idx:end_idx]\n",
        "\n",
        "    for file_path in batch_files:\n",
        "        file_name = os.path.basename(file_path)\n",
        "        dst_path = os.path.join(dst_folder, file_name)\n",
        "        shutil.move(file_path, dst_path)\n",
        "        print(f\"Przeniesiono plik: {file_name}\")"
      ],
      "metadata": {
        "id": "8wPtMOJXwreG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(json_data[0])"
      ],
      "metadata": {
        "id": "w0t_We8KlYl8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lista_sciezek = set([element[\"name\"] for element in json_data])"
      ],
      "metadata": {
        "id": "lTPQ7W-UJ1OD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dalsze prace"
      ],
      "metadata": {
        "id": "7p15s__0Zcsz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TODO\n",
        "\n",
        "1.\n",
        "Przygotowanie danych do treningu\n",
        "Format json -> yaml\n",
        "**DONE**\n",
        "\n",
        "2.\n",
        "Przejcie przez cay tutorial\n",
        "https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data\n",
        "https://docs.ultralytics.com/yolov5/tutorials/train_custom_data/#train-on-custom-data\n",
        "\n",
        "\n",
        "3.\n",
        "Plan eksperyment贸w:\n",
        "?\n",
        "\n",
        "4.\n",
        "Ewaluacja pretrenowanego modelu wasnych danych BDD100K dataset (pr贸ba wyznaczenia prdkoci)\n",
        "Ramka, wyrzucenie szum贸w (skoki prawo, lewo) regresja liniowa\n",
        "\n",
        "5.\n",
        "Wykorzystanie pre-trenowanego modelu na bazie coco128.yaml\n",
        "Dotrenowanie modelu na ograniczonej iloci klas zgodnie z labelami w coco128.yaml\n",
        "\n",
        "6.\n",
        "Wytrenowanie modelu od 0 na BDD100K DATASET (krok opcjonalny)\n",
        "\n",
        "\n",
        "## TODO_2\n",
        "\n",
        "1. DOCS postp pracy\n",
        "\n",
        "2. Na czym by trenowany yolov5s.pt i ten w tutorialu?\n"
      ],
      "metadata": {
        "id": "qKxV4sD6Z8nM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mam obrazek o pewnej rozdzielczoci i prostokt opisany wsp贸rzdnymi. Chc narysowa ramk, czego u偶y?"
      ],
      "metadata": {
        "id": "9WT9-rHbkevG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mam pre-trenowany model, kt贸ry rozpoznaje r贸偶ne klasy obiekt贸w. Zwraca ramk, ma klas samoch贸d, mog zaczc eksperymenty z wyznaczaniem prdkoci, a jednoczenie dotrenowywa model z moimi danymi"
      ],
      "metadata": {
        "id": "eqceFGMEdADT"
      }
    }
  ]
}